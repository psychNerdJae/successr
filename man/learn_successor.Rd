% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/learn.R
\name{learn_from_single_obs}
\alias{learn_from_single_obs}
\alias{learn_from_multiple_obs}
\alias{learn_successor}
\title{Learn successor relationships through observation}
\usage{
learn_from_single_obs(
  input,
  learning_rate,
  successor_horizon,
  previous_state,
  current_state,
  bidirectional = FALSE
)

learn_from_multiple_obs(
  input,
  observations,
  relation_value_col,
  learning_rate,
  successor_horizon,
  bidirectional = FALSE
)

learn_successor(
  input,
  observations,
  relation_value_col,
  learning_rates,
  successor_horizons,
  bidirectional = FALSE
)
}
\arguments{
\item{input}{Square NxN matrix}

\item{bidirectional}{Logical. Defaults to `FALSE`, which means that only
the `from-to` relationship gets updated. If set to `TRUE`, this function
will also update the `to-from` relationship.}

\item{observations}{Dataframe with columns `from` and `to`}

\item{relation_value_col}{The name of the column that encodes (or will
encode) the strength of relationship between two nodes.}

\item{learning_rates}{(List of) scalar(s) in [0, 1]}

\item{successor_horizons}{(List of) scalar(s) in [0, 1)}
}
\value{
A matrix with updated successor values, given the observation(s).
}
\description{
After observing relations between nodes (i.e., transitioning between
states), update the successor values.

Upon seeing a transition from \eqn{i} to \eqn{j}, the update equation for the
successor matrix \eqn{M} is \eqn{M(i) <- M(i) + \alpha \delta}, where
\eqn{\delta = onehot(i, j) + \gamma M(j) - M(i)}.

Technically, \eqn{M} should be indexed like a matrix. But for simplicity,
I write it like a single-input function that returns the associated row.
Therefore, the successor algorithm updates values in a row-wise manner.

The one-hot term is a vector the length of \eqn{M(i)}, which is filled with
zeros except for a single one (\eqn{1}) at the location \eqn{j}. Hence, the
one-hot vector encodes that when the agent was in state \eqn{i}, the next
observed state was \eqn{j}.

Where does the "successor" part of "successor representation/features" come
from? That's a reference to the middle part of the update equation. When you
encode the relationship between \eqn{i, j}, that's entirely accounted for by
the one-hot vector. But, you may want to also encode longer-range relations,
such that your representation of \eqn{i} not only includes the relationship
with \eqn{j}, but also the relationship between \eqn{j, k}. Therefore, you
will end up with larger successor values for direct connections, and smaller
values for indirect (e.g., long-range) connections.

The learning rate \eqn{\alpha} tempers how strongly the one-hot updates
the learned successor values. The lookahead horizon \eqn{\gamma} dictates
how strongly the successor state's relations are incorporated into the
update.
}
\examples{
`\%>\%` <- magrittr::`\%>\%`
karate_graph <- tidygraph::tbl_graph(edges = successr::karate, directed = F)
karate_walk <- karate_graph \%>\% generate_random_walk(1000)
karate_graph \%>\%
    initialize_successor() \%>\%
    learn_successor(karate_walk, c(0.1, 0.2), c(0, 0.8), TRUE)

}
